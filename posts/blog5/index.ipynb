{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: Auditing Allocative Bias\n",
    "author: Nhi Dang\n",
    "date: '2023-03-31'\n",
    "image: \"image.jpg\"\n",
    "description: \"This blog post fits a classifier using data from folktables and perform a bias audit for the algorithm.\"\n",
    "format: \n",
    "  html: \n",
    "    code-fold: show\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PUMS data for the state of Alabama\n",
    "\n",
    "There are approximately 48,000 rows of PUMS data in this data frame. Each one corresponds to an individual citizen of the state of Alabama who filled out the 2018 edition of the PUMS survey. We will filter through this dataset to predict employment status on the basis of demographics excluding race, and audit for racial bias. We will fit the training data on the Decision Tree Classifier model from scikit-learn and perform cross-validation to select the best max depth to achieve the highest accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RT</th>\n",
       "      <th>SERIALNO</th>\n",
       "      <th>DIVISION</th>\n",
       "      <th>SPORDER</th>\n",
       "      <th>PUMA</th>\n",
       "      <th>REGION</th>\n",
       "      <th>ST</th>\n",
       "      <th>ADJINC</th>\n",
       "      <th>PWGTP</th>\n",
       "      <th>AGEP</th>\n",
       "      <th>...</th>\n",
       "      <th>PWGTP71</th>\n",
       "      <th>PWGTP72</th>\n",
       "      <th>PWGTP73</th>\n",
       "      <th>PWGTP74</th>\n",
       "      <th>PWGTP75</th>\n",
       "      <th>PWGTP76</th>\n",
       "      <th>PWGTP77</th>\n",
       "      <th>PWGTP78</th>\n",
       "      <th>PWGTP79</th>\n",
       "      <th>PWGTP80</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P</td>\n",
       "      <td>2018GQ0000049</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1600</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1013097</td>\n",
       "      <td>75</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>140</td>\n",
       "      <td>74</td>\n",
       "      <td>73</td>\n",
       "      <td>7</td>\n",
       "      <td>76</td>\n",
       "      <td>75</td>\n",
       "      <td>80</td>\n",
       "      <td>74</td>\n",
       "      <td>7</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P</td>\n",
       "      <td>2018GQ0000058</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1900</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1013097</td>\n",
       "      <td>75</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>76</td>\n",
       "      <td>78</td>\n",
       "      <td>7</td>\n",
       "      <td>76</td>\n",
       "      <td>80</td>\n",
       "      <td>78</td>\n",
       "      <td>7</td>\n",
       "      <td>147</td>\n",
       "      <td>150</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P</td>\n",
       "      <td>2018GQ0000219</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1013097</td>\n",
       "      <td>118</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>117</td>\n",
       "      <td>121</td>\n",
       "      <td>123</td>\n",
       "      <td>205</td>\n",
       "      <td>208</td>\n",
       "      <td>218</td>\n",
       "      <td>120</td>\n",
       "      <td>19</td>\n",
       "      <td>123</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P</td>\n",
       "      <td>2018GQ0000246</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2400</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1013097</td>\n",
       "      <td>43</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>43</td>\n",
       "      <td>76</td>\n",
       "      <td>79</td>\n",
       "      <td>77</td>\n",
       "      <td>80</td>\n",
       "      <td>44</td>\n",
       "      <td>46</td>\n",
       "      <td>82</td>\n",
       "      <td>81</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P</td>\n",
       "      <td>2018GQ0000251</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2701</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1013097</td>\n",
       "      <td>16</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>28</td>\n",
       "      <td>17</td>\n",
       "      <td>30</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 286 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  RT       SERIALNO  DIVISION  SPORDER  PUMA  REGION  ST   ADJINC  PWGTP  \\\n",
       "0  P  2018GQ0000049         6        1  1600       3   1  1013097     75   \n",
       "1  P  2018GQ0000058         6        1  1900       3   1  1013097     75   \n",
       "2  P  2018GQ0000219         6        1  2000       3   1  1013097    118   \n",
       "3  P  2018GQ0000246         6        1  2400       3   1  1013097     43   \n",
       "4  P  2018GQ0000251         6        1  2701       3   1  1013097     16   \n",
       "\n",
       "   AGEP  ...  PWGTP71  PWGTP72  PWGTP73  PWGTP74  PWGTP75  PWGTP76  PWGTP77  \\\n",
       "0    19  ...      140       74       73        7       76       75       80   \n",
       "1    18  ...       76       78        7       76       80       78        7   \n",
       "2    53  ...      117      121      123      205      208      218      120   \n",
       "3    28  ...       43       76       79       77       80       44       46   \n",
       "4    25  ...        4        2       29       17       15       28       17   \n",
       "\n",
       "   PWGTP78  PWGTP79  PWGTP80  \n",
       "0       74        7       72  \n",
       "1      147      150       75  \n",
       "2       19      123       18  \n",
       "3       82       81        8  \n",
       "4       30       15        1  \n",
       "\n",
       "[5 rows x 286 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from folktables import ACSDataSource, ACSEmployment, BasicProblem, adult_filter\n",
    "import numpy as np\n",
    "\n",
    "STATE = \"AL\"\n",
    "\n",
    "data_source = ACSDataSource(survey_year='2018', \n",
    "                            horizon='1-Year', \n",
    "                            survey='person')\n",
    "\n",
    "acs_data = data_source.get_data(states=[STATE], download=True)\n",
    "\n",
    "acs_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Narrowing the features\n",
    "\n",
    "We’ll focus on a relatively small number of features in the modeling tasks of this blog post. Here are all the possible features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGEP</th>\n",
       "      <th>SCHL</th>\n",
       "      <th>MAR</th>\n",
       "      <th>RELP</th>\n",
       "      <th>DIS</th>\n",
       "      <th>ESP</th>\n",
       "      <th>CIT</th>\n",
       "      <th>MIG</th>\n",
       "      <th>MIL</th>\n",
       "      <th>ANC</th>\n",
       "      <th>NATIVITY</th>\n",
       "      <th>DEAR</th>\n",
       "      <th>DEYE</th>\n",
       "      <th>DREM</th>\n",
       "      <th>SEX</th>\n",
       "      <th>RAC1P</th>\n",
       "      <th>ESR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AGEP  SCHL  MAR  RELP  DIS  ESP  CIT  MIG  MIL  ANC  NATIVITY  DEAR  DEYE  \\\n",
       "0    19  18.0    5    17    2  NaN    1  3.0  4.0    1         1     2     2   \n",
       "1    18  18.0    5    17    2  NaN    1  3.0  4.0    1         1     2     2   \n",
       "2    53  17.0    5    16    1  NaN    1  1.0  4.0    2         1     2     2   \n",
       "3    28  19.0    5    16    2  NaN    1  1.0  2.0    1         1     2     2   \n",
       "4    25  12.0    5    16    1  NaN    1  3.0  4.0    1         1     2     2   \n",
       "\n",
       "   DREM  SEX  RAC1P  ESR  \n",
       "0   2.0    2      1  6.0  \n",
       "1   2.0    2      2  6.0  \n",
       "2   1.0    1      1  6.0  \n",
       "3   2.0    1      1  6.0  \n",
       "4   1.0    2      1  6.0  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_features=['AGEP', 'SCHL', 'MAR', 'RELP', 'DIS', 'ESP', 'CIT', 'MIG', 'MIL', 'ANC', 'NATIVITY', 'DEAR', 'DEYE', 'DREM', 'SEX', 'RAC1P', 'ESR']\n",
    "acs_data[possible_features].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_use = [f for f in possible_features if f not in [\"ESR\", \"RAC1P\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "EmploymentProblem = BasicProblem(\n",
    "    features=features_to_use,\n",
    "    target='ESR',\n",
    "    target_transform=lambda x: x == 1,\n",
    "    group='RAC1P',\n",
    "    preprocess=lambda x: x,\n",
    "    postprocess=lambda x: np.nan_to_num(x, -1),\n",
    ")\n",
    "\n",
    "features, label, group = EmploymentProblem.df_to_numpy(acs_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training and testing data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test, group_train, group_test = train_test_split(\n",
    "    features, label, group, test_size=0.2, random_state=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Inspection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of individuals: 57138\n",
      "Percent of employed individuals: 0.4091468041129222\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame(X_train, columns = features_to_use)\n",
    "df[\"group\"] = group_train\n",
    "df[\"label\"] = y_train\n",
    "\n",
    "print(f\"Number of individuals: {group_train.sum().sum()}\")\n",
    "print(f\"Percent of employed individuals: {y_train.mean()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of the 57,138 people in our training data, 40.95% have their target label equals to 1 - corresponding to those that are employed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "38221\n",
      "15638\n"
     ]
    }
   ],
   "source": [
    "p = (df['group'] == '0') & (df['label'] == '1')\n",
    "\n",
    "n = (df['group'] == 0)\n",
    "print(p.sum())\n",
    "print(n.size)\n",
    "print(y_train.sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training our data on Decision Tree Classifier\n",
    "\n",
    "We will train our model on the training data with the Decision Tree Classifier from scikit-learn. Additionally, we will perform cross validation to tune the max depth of the algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max depth = 5, score = 0.814\n",
      "Max depth = 4, score = 0.809\n",
      "Max depth = 3, score = 0.794\n",
      "Max depth = 2, score = 0.767\n",
      "Max depth = 1, score = 0.636\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "best_score_DT = 0       #keeping track of highest accuracy\n",
    "max_depth = 5           #iterator\n",
    "\n",
    "# train on decision tree classifier\n",
    "while max_depth != 0:\n",
    "    DT = make_pipeline(StandardScaler(), DecisionTreeClassifier(max_depth=max_depth))\n",
    "    DT.fit(X_train, y_train)\n",
    "    cv_scores = cross_val_score(DT, X_train, y_train, cv=5)\n",
    "    mean_score = cv_scores.mean()\n",
    "    print(f\"Max depth = {max_depth}, score = {mean_score.round(3)}\")\n",
    "\n",
    "    # keeping the list of columns for the max_depth that has the best score \n",
    "    if (DT.score(X_train, y_train) > best_score_DT):\n",
    "        best_score_DT = DT.score(X_train, y_train)\n",
    "        best_DT = DT\n",
    "        best_max_depth = max_depth\n",
    "    \n",
    "    max_depth += -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best max depth: 5\n",
      "Best score: 0.8143429004997252\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best max depth: {best_max_depth}\")\n",
    "print(f\"Best score: {best_score_DT}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auditting for Bias\n",
    "\n",
    "We will go ahead and audit for racial bias."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overall accuracy in predicting whether someone is employed is: \n",
      "0.8115320217664295\n"
     ]
    }
   ],
   "source": [
    "y_hat = best_DT.predict(X_test)\n",
    "\n",
    "print(\"The overall accuracy in predicting whether someone is employed is: \")\n",
    "print((y_hat == y_test).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PPV: 0.7652757078986587\n",
      "\n",
      "False negative rate: 0.15479204339963834\n",
      "\n",
      "False positive rate: 0.16817939135077417\n"
     ]
    }
   ],
   "source": [
    "matrix = confusion_matrix(y_test, y_hat)\n",
    "\n",
    "tp = matrix[1][1]\n",
    "tn = matrix[0][0]\n",
    "fp = matrix[0][1]\n",
    "fn = matrix[1][0]\n",
    "\n",
    "ppv = tp / (tp + fp)\n",
    "print(f\"\\nPPV: {ppv}\")\n",
    "\n",
    "print(f\"\\nFalse negative rate: {fn/(fn+tn)}\")\n",
    "print(f\"\\nFalse positive rate: {fp/(fp+tn)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used the confusion matrix function from sklearn to understand the kind of mistakes that the model most frequently makes. The overall accuracy of our model is 81%, with a positive predictive value of 0.77. Additionally, the overall false negative is 15.48% and overall false positive is 16.82%. It's clear that our model makes mistakes. Beyond that, it seems as though the model makes different kinds of error in its prediction for different groups."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By-Group Measures\n",
    "\n",
    "We/re going to compare the model's confusion matrices on the test data for white and black individuals to see if there exists bias in the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for white individuals is: \n",
      "0.810126582278481\n",
      "\n",
      "The accuracy for black individuals is: \n",
      "0.8151589242053789\n"
     ]
    }
   ],
   "source": [
    "print(\"The accuracy for white individuals is: \")\n",
    "print((y_hat == y_test)[group_test == 1].mean())\n",
    "\n",
    "print(\"\\nThe accuracy for black individuals is: \")\n",
    "print((y_hat == y_test)[group_test == 2].mean())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like the model attains similar accuracy score when predicting white and black individuals. It achieves 81.0% accuracy when predicting employment for white individuals and 81.5% for black individuals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PPV: 0.7782139352306182\n",
      "\n",
      "False negative for white individuals: 0.16580310880829016\n",
      "\n",
      "False positive for white individuals: 0.1670362158167036\n"
     ]
    }
   ],
   "source": [
    "# white sub group\n",
    "matrix_white = confusion_matrix(y_test[group_test == 1], y_hat[group_test == 1])\n",
    "\n",
    "tp = matrix_white[1][1]\n",
    "tn = matrix_white[0][0]\n",
    "fp = matrix_white[0][1]\n",
    "fn = matrix_white[1][0]\n",
    "\n",
    "ppv = tp / (tp + fp)\n",
    "print(f\"\\nPPV: {ppv}\")\n",
    "\n",
    "print(f\"\\nFalse negative for white individuals: {fn/(fn+tn)}\")\n",
    "print(f\"\\nFalse positive for white individuals: {fp/(fp+tn)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PPV: 0.7238805970149254\n",
      "\n",
      "False negative for black individuals: 0.12570507655116842\n",
      "\n",
      "False positive for black individuals: 0.16985462892119357\n"
     ]
    }
   ],
   "source": [
    "# black sub group\n",
    "matrix_black = confusion_matrix(y_test[group_test == 2], y_hat[group_test == 2])\n",
    "\n",
    "tp = matrix_black[1][1]\n",
    "tn = matrix_black[0][0]\n",
    "fp = matrix_black[0][1]\n",
    "fn = matrix_black[1][0]\n",
    "\n",
    "ppv = tp / (tp + fp)\n",
    "print(f\"\\nPPV: {ppv}\")\n",
    "\n",
    "print(f\"\\nFalse negative for black individuals: {fn/(fn+tn)}\")\n",
    "print(f\"\\nFalse positive for black individuals: {fp/(fp+tn)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When breaking down the matrices, the predictive value is a bit higher for the white individuals, with a difference of 5%. The model has similar false positive predictions for both black and white individuals. The false negative predictions are also comparable, except with a small difference of 4%. The model tends to predict unemployment for white individuals even when they are employed more than it does for the black individuals."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias Measures\n",
    "\n",
    "I conclude that the model is well calibrated because it reflects the same likelihood of recidivism irrespective of the individuals' group membership. In other words, it is free from predictive bias with respect to race. Additionally, since the false positive and false negative rates are similar across both group, the model satisfies approximate error rate balance. Lastly, our model achieves statistical parity because the proportion of individuals classified for employment is the same for each group."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concluding Discussions\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-0451",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
