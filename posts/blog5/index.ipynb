{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: Auditing Allocative Bias\n",
    "author: Nhi Dang\n",
    "date: '2023-03-31'\n",
    "image: \"image.jpg\"\n",
    "description: \"This blog post fits a classifier using data from folktables and perform a bias audit for the algorithm.\"\n",
    "format: \n",
    "  html: \n",
    "    code-fold: show\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PUMS data for the state of Alabama\n",
    "\n",
    "There are approximately 48,000 rows of PUMS data in this data frame. Each one corresponds to an individual citizen of the state of Alabama who filled out the 2018 edition of the PUMS survey. We will filter through this dataset to predict employment status on the basis of demographics excluding race, and audit for racial bias. We will fit the training data on the Decision Tree Classifier model from scikit-learn and perform cross-validation to select the best max depth to achieve the highest accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RT</th>\n",
       "      <th>SERIALNO</th>\n",
       "      <th>DIVISION</th>\n",
       "      <th>SPORDER</th>\n",
       "      <th>PUMA</th>\n",
       "      <th>REGION</th>\n",
       "      <th>ST</th>\n",
       "      <th>ADJINC</th>\n",
       "      <th>PWGTP</th>\n",
       "      <th>AGEP</th>\n",
       "      <th>...</th>\n",
       "      <th>PWGTP71</th>\n",
       "      <th>PWGTP72</th>\n",
       "      <th>PWGTP73</th>\n",
       "      <th>PWGTP74</th>\n",
       "      <th>PWGTP75</th>\n",
       "      <th>PWGTP76</th>\n",
       "      <th>PWGTP77</th>\n",
       "      <th>PWGTP78</th>\n",
       "      <th>PWGTP79</th>\n",
       "      <th>PWGTP80</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P</td>\n",
       "      <td>2018GQ0000049</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1600</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1013097</td>\n",
       "      <td>75</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>140</td>\n",
       "      <td>74</td>\n",
       "      <td>73</td>\n",
       "      <td>7</td>\n",
       "      <td>76</td>\n",
       "      <td>75</td>\n",
       "      <td>80</td>\n",
       "      <td>74</td>\n",
       "      <td>7</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P</td>\n",
       "      <td>2018GQ0000058</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1900</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1013097</td>\n",
       "      <td>75</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>76</td>\n",
       "      <td>78</td>\n",
       "      <td>7</td>\n",
       "      <td>76</td>\n",
       "      <td>80</td>\n",
       "      <td>78</td>\n",
       "      <td>7</td>\n",
       "      <td>147</td>\n",
       "      <td>150</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P</td>\n",
       "      <td>2018GQ0000219</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1013097</td>\n",
       "      <td>118</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>117</td>\n",
       "      <td>121</td>\n",
       "      <td>123</td>\n",
       "      <td>205</td>\n",
       "      <td>208</td>\n",
       "      <td>218</td>\n",
       "      <td>120</td>\n",
       "      <td>19</td>\n",
       "      <td>123</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P</td>\n",
       "      <td>2018GQ0000246</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2400</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1013097</td>\n",
       "      <td>43</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>43</td>\n",
       "      <td>76</td>\n",
       "      <td>79</td>\n",
       "      <td>77</td>\n",
       "      <td>80</td>\n",
       "      <td>44</td>\n",
       "      <td>46</td>\n",
       "      <td>82</td>\n",
       "      <td>81</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P</td>\n",
       "      <td>2018GQ0000251</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2701</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1013097</td>\n",
       "      <td>16</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>28</td>\n",
       "      <td>17</td>\n",
       "      <td>30</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 286 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  RT       SERIALNO  DIVISION  SPORDER  PUMA  REGION  ST   ADJINC  PWGTP  \\\n",
       "0  P  2018GQ0000049         6        1  1600       3   1  1013097     75   \n",
       "1  P  2018GQ0000058         6        1  1900       3   1  1013097     75   \n",
       "2  P  2018GQ0000219         6        1  2000       3   1  1013097    118   \n",
       "3  P  2018GQ0000246         6        1  2400       3   1  1013097     43   \n",
       "4  P  2018GQ0000251         6        1  2701       3   1  1013097     16   \n",
       "\n",
       "   AGEP  ...  PWGTP71  PWGTP72  PWGTP73  PWGTP74  PWGTP75  PWGTP76  PWGTP77  \\\n",
       "0    19  ...      140       74       73        7       76       75       80   \n",
       "1    18  ...       76       78        7       76       80       78        7   \n",
       "2    53  ...      117      121      123      205      208      218      120   \n",
       "3    28  ...       43       76       79       77       80       44       46   \n",
       "4    25  ...        4        2       29       17       15       28       17   \n",
       "\n",
       "   PWGTP78  PWGTP79  PWGTP80  \n",
       "0       74        7       72  \n",
       "1      147      150       75  \n",
       "2       19      123       18  \n",
       "3       82       81        8  \n",
       "4       30       15        1  \n",
       "\n",
       "[5 rows x 286 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from folktables import ACSDataSource, ACSEmployment, BasicProblem, adult_filter\n",
    "import numpy as np\n",
    "\n",
    "STATE = \"AL\"\n",
    "\n",
    "data_source = ACSDataSource(survey_year='2018', \n",
    "                            horizon='1-Year', \n",
    "                            survey='person')\n",
    "\n",
    "acs_data = data_source.get_data(states=[STATE], download=True)\n",
    "\n",
    "acs_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Narrowing the features\n",
    "\n",
    "We’ll focus on a relatively small number of features in the modeling tasks of this blog post. Here are all the possible features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGEP</th>\n",
       "      <th>SCHL</th>\n",
       "      <th>MAR</th>\n",
       "      <th>RELP</th>\n",
       "      <th>DIS</th>\n",
       "      <th>ESP</th>\n",
       "      <th>CIT</th>\n",
       "      <th>MIG</th>\n",
       "      <th>MIL</th>\n",
       "      <th>ANC</th>\n",
       "      <th>NATIVITY</th>\n",
       "      <th>DEAR</th>\n",
       "      <th>DEYE</th>\n",
       "      <th>DREM</th>\n",
       "      <th>SEX</th>\n",
       "      <th>RAC1P</th>\n",
       "      <th>ESR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AGEP  SCHL  MAR  RELP  DIS  ESP  CIT  MIG  MIL  ANC  NATIVITY  DEAR  DEYE  \\\n",
       "0    19  18.0    5    17    2  NaN    1  3.0  4.0    1         1     2     2   \n",
       "1    18  18.0    5    17    2  NaN    1  3.0  4.0    1         1     2     2   \n",
       "2    53  17.0    5    16    1  NaN    1  1.0  4.0    2         1     2     2   \n",
       "3    28  19.0    5    16    2  NaN    1  1.0  2.0    1         1     2     2   \n",
       "4    25  12.0    5    16    1  NaN    1  3.0  4.0    1         1     2     2   \n",
       "\n",
       "   DREM  SEX  RAC1P  ESR  \n",
       "0   2.0    2      1  6.0  \n",
       "1   2.0    2      2  6.0  \n",
       "2   1.0    1      1  6.0  \n",
       "3   2.0    1      1  6.0  \n",
       "4   1.0    2      1  6.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_features=['AGEP', 'SCHL', 'MAR', 'RELP', 'DIS', 'ESP', 'CIT', 'MIG', 'MIL', 'ANC', 'NATIVITY', 'DEAR', 'DEYE', 'DREM', 'SEX', 'RAC1P', 'ESR']\n",
    "acs_data[possible_features].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_use = [f for f in possible_features if f not in [\"ESR\", \"RAC1P\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EmploymentProblem = BasicProblem(\n",
    "    features=features_to_use,\n",
    "    target='ESR',\n",
    "    target_transform=lambda x: x == 1,\n",
    "    group='RAC1P',\n",
    "    preprocess=lambda x: x,\n",
    "    postprocess=lambda x: np.nan_to_num(x, -1),\n",
    ")\n",
    "\n",
    "features, label, group = EmploymentProblem.df_to_numpy(acs_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training and testing data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test, group_train, group_test = train_test_split(\n",
    "    features, label, group, test_size=0.2, random_state=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Inspection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of individuals: 38221\n",
      "Percent of employed individuals: 0.4091468041129222\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame(X_train, columns = features_to_use)\n",
    "df[\"group\"] = group_train\n",
    "df[\"label\"] = y_train\n",
    "\n",
    "print(f\"Number of individuals: {group_train.size}\")\n",
    "print(f\"Percent of employed individuals: {y_train.mean()}\")\n",
    "\n",
    "# mean = percentage of 1, percentage of that group being employed\n",
    "# sum= total num of 1\n",
    "# len = total num in that group regardless of employment "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of the 38,221 people in our training data, 40.95% have their target label equals to 1 - corresponding to those that are employed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# running split and train again, now without filtering out RAC1P\n",
    "\n",
    "DataInspection = BasicProblem(\n",
    "    features=features_to_use,\n",
    "    target='ESR',\n",
    "    target_transform=lambda x: x == 1,\n",
    "    preprocess=lambda x: x,\n",
    "    postprocess=lambda x: np.nan_to_num(x, -1),\n",
    ")\n",
    "\n",
    "features_new, label_new, group_new = DataInspection.df_to_numpy(acs_data)\n",
    "\n",
    "X_train_new, X_test_new, y_train_new, y_test_new, group_train_new, group_test_new = train_test_split(\n",
    "    features_new, label_new, group_new, test_size=0.2, random_state=0)\n",
    "\n",
    "# does group train new contain multiple values\n",
    "\n",
    "df_new = pd.DataFrame(X_train_new, columns = features_to_use)\n",
    "df_new[\"group\"] = group_train_new\n",
    "df_new[\"label\"] = y_train_new\n",
    "\n",
    "#acs_data.groupby('SEX')[['ESR']].aggregate([np.mean, len]).round(2)\n",
    "\n",
    "#df_new.groupby('group')[['label']].aggregate([np.mean, len]).round(2)\n",
    "\n",
    "#df_new.head()\n",
    "\n",
    "group_train_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 676.25x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "g = sns.catplot(\n",
    "    data=df_new, kind=\"bar\",\n",
    "    x=\"group\", y=\"label\", hue = \"SEX\",\n",
    "    errorbar=\"sd\", palette=\"dark\", alpha=.6, height=6\n",
    ")\n",
    "g.despine(left=True)\n",
    "g.set_axis_labels(\"Race\", \"Employment\")\n",
    "g.legend.set_title(\"\")\n",
    "g.savefig(\"image.jpg\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training our data on Decision Tree Classifier\n",
    "\n",
    "We will train our model on the training data with the Decision Tree Classifier from scikit-learn. Additionally, we will perform cross validation to tune the max depth of the algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max depth = 5, score = 0.814\n",
      "Max depth = 4, score = 0.809\n",
      "Max depth = 3, score = 0.794\n",
      "Max depth = 2, score = 0.767\n",
      "Max depth = 1, score = 0.636\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "best_score_DT = 0       #keeping track of highest accuracy\n",
    "max_depth = 5           #iterator\n",
    "\n",
    "# train on decision tree classifier\n",
    "while max_depth != 0:\n",
    "    DT = make_pipeline(StandardScaler(), DecisionTreeClassifier(max_depth=max_depth))\n",
    "    DT.fit(X_train, y_train)\n",
    "    cv_scores = cross_val_score(DT, X_train, y_train, cv=5)\n",
    "    mean_score = cv_scores.mean()\n",
    "    print(f\"Max depth = {max_depth}, score = {mean_score.round(3)}\")\n",
    "\n",
    "    # keeping the list of columns for the max_depth that has the best score \n",
    "    if (DT.score(X_train, y_train) > best_score_DT):\n",
    "        best_score_DT = DT.score(X_train, y_train)\n",
    "        best_DT = DT\n",
    "        best_max_depth = max_depth\n",
    "    \n",
    "    max_depth += -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best max depth: 5\n",
      "Best score: 0.8143429004997252\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best max depth: {best_max_depth}\")\n",
    "print(f\"Best score: {best_score_DT}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auditting for Bias\n",
    "\n",
    "We will go ahead and audit for racial bias."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overall accuracy in predicting whether someone is employed is: \n",
      "0.8115320217664295\n"
     ]
    }
   ],
   "source": [
    "y_hat = best_DT.predict(X_test)\n",
    "\n",
    "print(\"The overall accuracy in predicting whether someone is employed is: \")\n",
    "print((y_hat == y_test).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PPV: 0.7652757078986587\n",
      "\n",
      "False negative rate: 0.15479204339963834\n",
      "\n",
      "False positive rate: 0.16817939135077417\n"
     ]
    }
   ],
   "source": [
    "matrix = confusion_matrix(y_test, y_hat)\n",
    "\n",
    "tp = matrix[1][1]\n",
    "tn = matrix[0][0]\n",
    "fp = matrix[0][1]\n",
    "fn = matrix[1][0]\n",
    "\n",
    "ppv = tp / (tp + fp)\n",
    "print(f\"\\nPPV: {ppv}\")\n",
    "\n",
    "print(f\"\\nFalse negative rate: {fn/(fn+tn)}\")\n",
    "print(f\"\\nFalse positive rate: {fp/(fp+tn)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used the confusion matrix function from sklearn to understand the kind of mistakes that the model most frequently makes. The overall accuracy of our model is 81%, with a positive predictive value of 0.77. Additionally, the overall false negative is 15.48% and overall false positive is 16.82%. It's clear that our model makes mistakes. Beyond that, it seems as though the model makes different kinds of error in its prediction for different groups."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By-Group Measures\n",
    "\n",
    "We're going to compare the model's confusion matrices on the test data for white and black individuals to see if there exists bias in the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for white individuals is: \n",
      "0.810126582278481\n",
      "\n",
      "The accuracy for black individuals is: \n",
      "0.8151589242053789\n"
     ]
    }
   ],
   "source": [
    "print(\"The accuracy for white individuals is: \")\n",
    "print((y_hat == y_test)[group_test == 1].mean())\n",
    "\n",
    "print(\"\\nThe accuracy for black individuals is: \")\n",
    "print((y_hat == y_test)[group_test == 2].mean())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like the model attains similar accuracy score when predicting white and black individuals. It achieves 81.0% accuracy when predicting employment for white individuals and 81.5% for black individuals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PPV: 0.7782139352306182\n",
      "\n",
      "False negative for white individuals: 0.16580310880829016\n",
      "\n",
      "False positive for white individuals: 0.1670362158167036\n"
     ]
    }
   ],
   "source": [
    "# white sub group\n",
    "matrix_white = confusion_matrix(y_test[group_test == 1], y_hat[group_test == 1])\n",
    "\n",
    "tp = matrix_white[1][1]\n",
    "tn = matrix_white[0][0]\n",
    "fp = matrix_white[0][1]\n",
    "fn = matrix_white[1][0]\n",
    "\n",
    "ppv = tp / (tp + fp)\n",
    "print(f\"\\nPPV: {ppv}\")\n",
    "\n",
    "print(f\"\\nFalse negative for white individuals: {fn/(fn+tn)}\")\n",
    "print(f\"\\nFalse positive for white individuals: {fp/(fp+tn)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PPV: 0.7238805970149254\n",
      "\n",
      "False negative for black individuals: 0.12570507655116842\n",
      "\n",
      "False positive for black individuals: 0.16985462892119357\n"
     ]
    }
   ],
   "source": [
    "# black sub group\n",
    "matrix_black = confusion_matrix(y_test[group_test == 2], y_hat[group_test == 2])\n",
    "\n",
    "tp = matrix_black[1][1]\n",
    "tn = matrix_black[0][0]\n",
    "fp = matrix_black[0][1]\n",
    "fn = matrix_black[1][0]\n",
    "\n",
    "ppv = tp / (tp + fp)\n",
    "print(f\"\\nPPV: {ppv}\")\n",
    "\n",
    "print(f\"\\nFalse negative for black individuals: {fn/(fn+tn)}\")\n",
    "print(f\"\\nFalse positive for black individuals: {fp/(fp+tn)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When breaking down the matrices, the predictive value is a bit higher for the white individuals, with a difference of 5%. The model has similar false positive predictions for both black and white individuals. The false negative predictions are also comparable, except with a small difference of 4%. The model tends to predict unemployment for white individuals even when they are employed more than it does for the black individuals."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias Measures\n",
    "\n",
    "I conclude that the model is well calibrated because it reflects the same likelihood of recidivism irrespective of the individuals' group membership. In other words, it is free from predictive bias with respect to race. Additionally, since the false positive and false negative rates are similar across both group, the model satisfies approximate error rate balance. Lastly, our model achieves statistical parity because the proportion of individuals classified for employment is the same for each group."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concluding Discussions\n",
    "\n",
    "My model predicts employment status based on basic demographics such as age, educational attainment, and other features excluding race. This model could potentially be used by companies and organizations seeking to automate their hiring process. This will allow for more efficient and less costly hiring process, but at what costs? Even though the model is well calibrated, deploying it for large-scale prediction in commercial or governmental settings could create harm. A model free from predictive bias with respect to race like ours can still be problematic. \n",
    "\n",
    "This model was trained based on features that carry implicit bias, features that should not determine someone's employment. Some of these features are: employment status of parents, marital status, nativity (wether or not the person was born in the U.S.), person's current income, etc... Clearly, these features should not characterize someone's employability. Thus, even though our model passes the bias measures in respect to race, it still carries implicit biases. \n",
    "\n",
    "These biases stem from the data collection process and the kind of data that was collected. I propose for a more carefully chosen set of questions, focusing on the person's achievement and potential - rather than their family history and other factors that don't equate to employability. If someone is already set up at a disadvantage from the start, we should not use their history to predict their potential. \n",
    "\n",
    "Additionally, the model only achieves 81% accuracy rate. This begs the question of wether or not this model is reliable enough to be used for predicting someone's future. Predicting someone's employability is an important task that can lead to grave consequences. Thus, there should be more efforts made to understand how forms of data bias can affect the ability to assess models with respect to different fairness criteria. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-0451",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
